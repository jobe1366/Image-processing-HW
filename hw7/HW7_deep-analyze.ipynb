{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "17tXWFmYg1u7"
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def __convert_to_one_hot(vector, num_classes):\n",
    "    result = np.zeros(shape=[len(vector), num_classes])\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def __resize_image(src_image, dst_image_height, dst_image_width):\n",
    "    src_image_height = src_image.shape[0]\n",
    "    src_image_width = src_image.shape[1]\n",
    "\n",
    "    if src_image_height > dst_image_height or src_image_width > dst_image_width:\n",
    "        height_scale = dst_image_height / src_image_height\n",
    "        width_scale = dst_image_width / src_image_width\n",
    "        scale = min(height_scale, width_scale)\n",
    "        img = cv2.resize(src=src_image, dsize=(0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    else:\n",
    "        img = src_image\n",
    "\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "\n",
    "    dst_image = np.zeros(shape=[dst_image_height, dst_image_width], dtype=np.uint8)\n",
    "\n",
    "    y_offset = (dst_image_height - img_height) // 2\n",
    "    x_offset = (dst_image_width - img_width) // 2\n",
    "\n",
    "    dst_image[y_offset:y_offset+img_height, x_offset:x_offset+img_width] = img\n",
    "\n",
    "    return dst_image\n",
    "\n",
    "\n",
    "def read_hoda_cdb(file_name):\n",
    "    with open(file_name, 'rb') as binary_file:\n",
    "\n",
    "        data = binary_file.read()\n",
    "\n",
    "        offset = 0\n",
    "\n",
    "        # read private header\n",
    "\n",
    "        yy = struct.unpack_from('H', data, offset)[0]\n",
    "        offset += 2\n",
    "\n",
    "        m = struct.unpack_from('B', data, offset)[0]\n",
    "        offset += 1\n",
    "\n",
    "        d = struct.unpack_from('B', data, offset)[0]\n",
    "        offset += 1\n",
    "\n",
    "        H = struct.unpack_from('B', data, offset)[0]\n",
    "        offset += 1\n",
    "\n",
    "        W = struct.unpack_from('B', data, offset)[0]\n",
    "        offset += 1\n",
    "\n",
    "        TotalRec = struct.unpack_from('I', data, offset)[0]\n",
    "        offset += 4\n",
    "\n",
    "        LetterCount = struct.unpack_from('128I', data, offset)\n",
    "        offset += 128 * 4\n",
    "\n",
    "        imgType = struct.unpack_from('B', data, offset)[0]  # 0: binary, 1: gray\n",
    "        offset += 1\n",
    "\n",
    "        Comments = struct.unpack_from('256c', data, offset)\n",
    "        offset += 256 * 1\n",
    "\n",
    "        Reserved = struct.unpack_from('245c', data, offset)\n",
    "        offset += 245 * 1\n",
    "\n",
    "        if (W > 0) and (H > 0):\n",
    "            normal = True\n",
    "        else:\n",
    "            normal = False\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(TotalRec):\n",
    "\n",
    "            StartByte = struct.unpack_from('B', data, offset)[0]  # must be 0xff\n",
    "            offset += 1\n",
    "\n",
    "            label = struct.unpack_from('B', data, offset)[0]\n",
    "            offset += 1\n",
    "\n",
    "            if not normal:\n",
    "                W = struct.unpack_from('B', data, offset)[0]\n",
    "                offset += 1\n",
    "\n",
    "                H = struct.unpack_from('B', data, offset)[0]\n",
    "                offset += 1\n",
    "\n",
    "            ByteCount = struct.unpack_from('H', data, offset)[0]\n",
    "            offset += 2\n",
    "\n",
    "            image = np.zeros(shape=[H, W], dtype=np.uint8)\n",
    "\n",
    "            if imgType == 0:\n",
    "                # Binary\n",
    "                for y in range(H):\n",
    "                    bWhite = True\n",
    "                    counter = 0\n",
    "                    while counter < W:\n",
    "                        WBcount = struct.unpack_from('B', data, offset)[0]\n",
    "                        offset += 1\n",
    "                        # x = 0\n",
    "                        # while x < WBcount:\n",
    "                        #     if bWhite:\n",
    "                        #         image[y, x + counter] = 0  # Background\n",
    "                        #     else:\n",
    "                        #         image[y, x + counter] = 255  # ForeGround\n",
    "                        #     x += 1\n",
    "                        if bWhite:\n",
    "                            image[y, counter:counter + WBcount] = 0  # Background\n",
    "                        else:\n",
    "                            image[y, counter:counter + WBcount] = 255  # ForeGround\n",
    "                        bWhite = not bWhite  # black white black white ...\n",
    "                        counter += WBcount\n",
    "            else:\n",
    "                # GrayScale mode\n",
    "                data = struct.unpack_from('{}B'.format(W * H), data, offset)\n",
    "                offset += W * H\n",
    "                image = np.asarray(data, dtype=np.uint8).reshape([W, H]).T\n",
    "\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "\n",
    "def read_hoda_dataset(dataset_path, images_height=32, images_width=32, one_hot=False, reshape=True):\n",
    "    images, labels = read_hoda_cdb(dataset_path)\n",
    "    assert len(images) == len(labels)\n",
    "\n",
    "    X = np.zeros(shape=[len(images), images_height, images_width], dtype=np.float32)\n",
    "    Y = np.zeros(shape=[len(labels)], dtype=np.int)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        # Image resizing.\n",
    "        image = __resize_image(src_image=image, dst_image_height=images_height, dst_image_width=images_width)\n",
    "        # Image normalization.\n",
    "        image = image / 255\n",
    "        # Image binarization.\n",
    "        image = np.where(image >= 0.5, 1, 0)\n",
    "        # Image.\n",
    "        X[i] = image\n",
    "        # Label.\n",
    "        Y[i] = labels[i]\n",
    "\n",
    "    if one_hot:\n",
    "        Y = __convert_to_one_hot(Y, 10).astype(dtype=np.float32)\n",
    "    else:\n",
    "        Y = Y.astype(dtype=np.float32)\n",
    "\n",
    "    if reshape:\n",
    "        X = X.reshape(-1, images_height * images_width)\n",
    "    else:\n",
    "        X = X.reshape(-1, images_height, images_width, 1)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCdoFA33RmLy",
    "outputId": "392b3723-0ca8-493e-9752-26ef817526a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive' , timeout_ms=3600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z1bngLF0SKAH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#!unzip \"/content/drive/My Drive/DigitDB.zip\" -d \"/content/drive/My Drive/\"\n",
    "x_train, y_train = read_hoda_cdb('/content/drive/My Drive/Train 60000.cdb')\n",
    "x_test, y_test = read_hoda_cdb('/content/drive/My Drive/Test 20000.cdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fx_nehneUZ9x"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "X_train=[]\n",
    "for imgs in x_train:\n",
    "  X_train.append(np.array(cv2.resize(imgs ,(30 , 30), interpolation = cv2.INTER_AREA ) ,dtype='float64'))\n",
    "\n",
    "X_test=[]\n",
    "for imgs in x_test:\n",
    "  X_test.append(np.array(cv2.resize(imgs ,(30 , 30), interpolation = cv2.INTER_AREA ) ,dtype='float64' ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gMWfgvYd7_jq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Layer, Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V59-AmgOWSYd",
    "outputId": "b263916e-f87f-4486-a4cf-a118b9525161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: \t (60000, 30, 30, 1)\n",
      "X_test shape: \t (20000, 30, 30, 1)\n",
      "y_test shape: \t (60000, 10)\n",
      "y_test shape: \t (20000, 10)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing of  train and test data  \n",
    "\n",
    "X_train= np.array(X_train)\n",
    "X_train = X_train.reshape(60000, 30, 30, 1)\n",
    "X_test= np.array(X_test)\n",
    "X_test = X_test.reshape(20000, 30, 30, 1)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "y_train= np.array(y_train)\n",
    "y_test= np.array(y_test)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "print('X_train shape: \\t', X_train.shape )\n",
    "print('X_test shape: \\t', X_test.shape )\n",
    "print('y_test shape: \\t', y_train.shape )\n",
    "print('y_test shape: \\t', y_test.shape )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kWpDj8t2WZi2"
   },
   "outputs": [],
   "source": [
    "def CNN_model():\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, (3, 3), activation = 'relu', padding='same', input_shape=X_train.shape[1:]))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(32, (3, 3), activation = 'relu', padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, activation = 'relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(10, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9), metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXxUTvvOIfsv",
    "outputId": "a29c557c-7161-41c7-c081-a172aa27d905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 437,610\n",
      "Trainable params: 436,458\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 60\n",
    "epochs = 25\n",
    "\n",
    "first_model = CNN_model()\n",
    "first_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rv28i9E5LNml",
    "outputId": "83f5410a-9721-4d67-e5fc-1f697f8e7e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1000/1000 [==============================] - 10s 9ms/step - loss: 0.6374 - accuracy: 0.8086 - val_loss: 0.0970 - val_accuracy: 0.9696\n",
      "Epoch 2/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0902 - accuracy: 0.9730 - val_loss: 0.0657 - val_accuracy: 0.9790\n",
      "Epoch 3/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0646 - accuracy: 0.9805 - val_loss: 0.0512 - val_accuracy: 0.9845\n",
      "Epoch 4/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0533 - accuracy: 0.9845 - val_loss: 0.0440 - val_accuracy: 0.9853\n",
      "Epoch 5/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 0.0369 - val_accuracy: 0.9877\n",
      "Epoch 6/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0359 - accuracy: 0.9894 - val_loss: 0.0373 - val_accuracy: 0.9879\n",
      "Epoch 7/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0340 - accuracy: 0.9906 - val_loss: 0.0330 - val_accuracy: 0.9887\n",
      "Epoch 8/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0331 - accuracy: 0.9903 - val_loss: 0.0332 - val_accuracy: 0.9883\n",
      "Epoch 9/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0319 - accuracy: 0.9906 - val_loss: 0.0317 - val_accuracy: 0.9897\n",
      "Epoch 10/25\n",
      "1000/1000 [==============================] - 8s 9ms/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.0278 - val_accuracy: 0.9906\n",
      "Epoch 11/25\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.0270 - val_accuracy: 0.9912\n",
      "Epoch 12/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0256 - val_accuracy: 0.9919\n",
      "Epoch 13/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.0237 - val_accuracy: 0.9924\n",
      "Epoch 14/25\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.0237 - val_accuracy: 0.9924\n",
      "Epoch 15/25\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.0269 - val_accuracy: 0.9913\n",
      "Epoch 16/25\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.0230 - val_accuracy: 0.9927\n",
      "Epoch 17/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.0219 - val_accuracy: 0.9931\n",
      "Epoch 18/25\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0216 - val_accuracy: 0.9937\n",
      "Epoch 19/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0215 - val_accuracy: 0.9932\n",
      "Epoch 20/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.0207 - val_accuracy: 0.9934\n",
      "Epoch 21/25\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0204 - val_accuracy: 0.9939\n",
      "Epoch 22/25\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.0204 - val_accuracy: 0.9935\n",
      "Epoch 23/25\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0205 - val_accuracy: 0.9941\n",
      "Epoch 24/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0199 - val_accuracy: 0.9944\n",
      "Epoch 25/25\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0197 - val_accuracy: 0.9944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first_history = first_model.fit( X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0Pf2c_unVj4",
    "outputId": "0e7d61da-0c42-4e55-8177-ceab4bd23c93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : \t  0.9987499713897705\n",
      "\n",
      "Test accuracy : \t   0.9944000244140625\n",
      "\n",
      "\n",
      "Confusion Matrix =  \n",
      "\n",
      "\n",
      "[[1980   11    2    0    0    5    0    2    0    0]\n",
      " [   2 1997    0    0    1    0    0    0    0    0]\n",
      " [   0    2 1994    1    0    0    0    1    0    2]\n",
      " [   0    0   23 1970    5    1    0    0    1    0]\n",
      " [   0    0    4    4 1990    0    0    1    0    1]\n",
      " [   6    0    3    0    1 1989    0    0    1    0]\n",
      " [   0    4    0    0    0    2 1987    0    0    7]\n",
      " [   2    4    1    0    0    0    0 1993    0    0]\n",
      " [   0    1    0    0    0    0    0    0 1999    0]\n",
      " [   1    5    0    0    0    2    3    0    0 1989]] \n"
     ]
    }
   ],
   "source": [
    "y_pred = first_model.predict(X_test)\n",
    "y_pred = [np.argmax(y_pred[i]) for i in range(len(y_pred))]\n",
    "y_true = [np.argmax(y_test[i]) for i in range(len(y_test))]\n",
    "\n",
    "train_scores = first_model.evaluate(X_train, y_train, verbose = 0)\n",
    "test_scores = first_model.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "print('Train accuracy : \\t ', train_scores[1])\n",
    "print('\\nTest accuracy : \\t  ', test_scores[1])\n",
    "\n",
    "  \n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print('\\n\\nConfusion Matrix =  \\n\\n\\n{} ' .format(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWXOHqFAvaE2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HW_7_Q_4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
